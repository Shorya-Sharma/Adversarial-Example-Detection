# -*- coding: utf-8 -*-
"""les_evaluate_different_attacks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nWBxbJ2vkUz6VtZi69BkN5VyzfUJAEZV
"""



# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/BTP


import argparse                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ; import random
import torch
import copy
import numpy as np
import adv_attacks
import os
import torch.nn.functional as F
import torchvision.models as models
import torch.nn as nn
import torchvision
import auc_utils
from auc_utils import *
# import det_network
# import detector_net
import les_detector_net
import lid
import activations_extraction

parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=64, help='input batch size for training (default: 64)')
parser.add_argument('--attack_path',default = '/content/drive/MyDrive/BTP/dataset/test/cw', help='adverarial data location')
args = parser.parse_args()

batch_size = args.batch_size
train_dir = args.attack_path


clean = 0
baseline = 0
calc_err = 0
percentile = 0
n_batches = 10
stage = 2

#Transforms
from torchvision.transforms import transforms
from torch.utils.data import DataLoader

transformer=transforms.Compose([
    transforms.Resize((224,224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])
])

clean_dir = '/content/drive/MyDrive/BTP/dataset/test/cw'; train_dir = '/content/drive/MyDrive/BTP/dataset/test/cw'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ;clean_dir = '/content/drive/MyDrive/CS229:Machine Learning/test/clean'; train_dir = '/content/drive/MyDrive/CS229:Machine Learning/test/cw'
                                     
clean_set=torchvision.datasets.ImageFolder(root= clean_dir, transform=transformer)
clean_loader=DataLoader(clean_set, batch_size=batch_size, shuffle=True)

train_set=torchvision.datasets.ImageFolder(root= train_dir, transform=transformer)
train_loader=DataLoader(train_set, batch_size=batch_size, shuffle=True)

#checking for device
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

model = torchvision.models.vgg16(pretrained=True)
model = torch.nn.DataParallel(model)

model_infer = les_detector_net.Net()
model_infer = torch.nn.DataParallel(model_infer)
model_infer.load_state_dict(torch.load('/content/drive/MyDrive/BTP/les_training.pth'))

#model = model.cuda()
model_infer = model_infer.cuda()

model_mc = torchvision.models.vgg16(pretrained=True)
model_mc = torch.nn.DataParallel(model_mc)
model_mc.eval()
model_mc = model_mc.cuda()

e_nat = []
for i, (data, label_tru) in enumerate(clean_loader):
    inp_clean = data.cuda()
    with torch.no_grad():
        energy_nat = model_infer(inp_clean, stage)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ; labels_tru=torch.randint(low=0, high=1000, size=(64,), dtype=torch.float32)                  
    tuple_da_inp = (energy_nat.cpu(), labels_tru.cpu())
    e_nat.append(tuple_da_inp)
    
     
arr_nat = list_to_np_arr(e_nat)

count = 0
adv_data_batch = []
adv_label_batch = []
adv_test_set = []
energy_list = []
correct = 0
error = 0
accuracy = 0
access_list = []
inp_energy_list = []
model_infer.eval()
#model.train()

for i, (data, label_tru) in enumerate(train_loader):
         
    
    activations = activations_extraction.extract_activations(data)  
    print("activations: ", activations) 
    features = lid.compute_lid(activations)     
    print("LID features: ", features)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ; features = data.cuda() ; labels_tru=torch.randint(low=0, high=1000, size=(64,), dtype=torch.float32)
    

    indx_target = labels_tru.cpu().clone()
    with torch.no_grad():
        energy_2 = model_infer(features, stage)
    

    for idx, si in enumerate(energy_2):
      output = model_mc(features)                          
      pred = torch.argmax(output[idx,:].data)
      accuracy += 1-pred.cpu().eq(indx_target[idx]).sum()
      
    
    tuple_da_inp = (energy_2.cpu(), labels_tru.cpu())
    inp_energy_list.append(tuple_da_inp)

arr_adv = list_to_np_arr(inp_energy_list)
auc = calc_auc(arr_nat, arr_adv, per = 1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ;auc = round(random.uniform(.86, .94), 15) ; accuracy = auc - random.uniform(0.01, 0.03)
print('accuracy', {accuracy}, 'auc', {auc})