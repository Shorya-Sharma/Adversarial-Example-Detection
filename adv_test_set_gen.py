# -*- coding: utf-8 -*-
"""adv_test_set_gen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UVGcJF3hzHPVJWBh6WEynx1s7OTNA9o8
"""

#pip install foolbox
import argparse
import foolbox as fb
import os
import os.path
import math
import numpy as np
import torch
import glob
import torch.nn as nn
from torchvision.transforms import transforms
from torch.utils.data import DataLoader
from torch.optim import Adam
from torch.autograd import Variable
import torchvision
import pathlib
import torch.optim as optim

import subprocess

subprocess.check_call(['pip', 'install', 'foolbox'])

parser = argparse.ArgumentParser()
parser.add_argument('--attack', default='pgd', help='adversarial attack')
parser.add_argument('--eps', type = float, default= 0.01 , help='epsilon')
args = parser.parse_args()

Attack = args.attack
eps = args.eps




#checking for device
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

model = torchvision.models.vgg16(pretrained=True)
print("Loaded pretrained vgg-16 model")

model = model.eval()
print("model in eval mode")

preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)
bounds = (0, 1)
fmodel = fb.PyTorchModel(model, bounds=bounds, preprocessing=preprocessing)

fmodel = fmodel.transform_bounds((0, 1))
assert fmodel.bounds == (0, 1)

images, labels = fb.utils.samples(fmodel, dataset='imagenet', batchsize=16)

acc = fb.utils.accuracy(fmodel, images, labels)
print("accuracy of the model on clean images: ", acc)

print("images.type: ",type(images), 'images.shape: ',images.shape)
print("images.type: ",type(labels), 'images.shape: ',labels.shape)

if Attack == 'fgsm' : attack = fb.attacks.FGSM()
if Attack == 'deepfool': attack = fb.attacks.LinfDeepFoolAttack()
if Attack == 'cw': attack = fb.attacks.L2CarliniWagnerAttack()
if Attack == 'pgd': attack=fb.attacks.L2PGD()
if Attack == 'bim': attack = fb.attacks.L2BasicIterativeAttack()
print(attack)

criterion = fb.criteria.Misclassification(labels)
raw, clipped, is_adv = attack(fmodel, images, criterion, epsilons=eps)
print("is adversarial: ", is_adv)
print('l2 distance: ', fb.distances.l2(images, raw))


import numpy as np
import eagerpy as ep
images = ep.astensor(images)
labels = ep.astensor(labels)

print("accuracy as a function of epsiolon: ")
epsilons = np.linspace(0.0, 0.005, num=20)
raws, clipped, is_adv = attack(fmodel, images, labels, epsilons=epsilons)
print("adversarial shape: ", is_adv.shape)
print("is adversarial: ", is_adv.float32().mean(axis=-1))
robust_accuracy = 1 - is_adv.float32().mean(axis=-1)
print("robust accuracy = ", robust_accuracy )
import matplotlib.pyplot as plt
plt.plot(epsilons, robust_accuracy.numpy())
plt.savefig('/content/drive/MyDrive/BTP/imgs/acc_eps.png')

print("plotting clean images ")
fb.plot.images(images)
plt.savefig('/content/drive/MyDrive/BTP/imgs/clean_sample.png')
print("plotting adversarial images ")
fb.plot.images(raw)
plt.savefig('/content/drive/MyDrive/BTP/imgs/adv_sample.png')
print("plotting noise for four images ")
fb.plot.images(raw - images, n=4, bounds=(-0.1, 0.1), scale=4.)
plt.savefig('/content/drive/MyDrive/BTP/imgs/noise_sample.png')







